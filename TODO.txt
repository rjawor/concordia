DONE 1. lokalizowane to_lower (wykorzystać utf8case, naprawić testy)
DONE 2. anonimizacja zdań
DONE 3. Dzielenie zdań (max 255 tokenów)




DONE Anubis search się komplikuje! Przy tworzeniu obiektu tmMatches dla przykładu trzeba podać id przykładu, długość patternu i długość przykładu. Dwa pierwsze mamy, ale niestety nie ma skąd wziąć długości przykładu. Pamiętamy tylko offset sufiksu.

DONE 1. Bitwise operators (i stałe!) przy rozmiarze index character oraz markerów
IN PROGRESS 2. Wykonać anubis search na nowych markerach z długością zdania
3. Multi-threading?

- concordia-server
- zastanowić się nad empty hash examples (rozwiązanie: w ogóle nie szukać fraz o pustym hashu, rzucać wyjątek).
- wyłączyć stopWords
- puścić 100% search test na jrc
- wyszukiwanie zdania: wyszukanie najdłuższych pasujących fragmentów Anubisem, 1D (approximate) bin packing


zastanowić się nad optymalizacją:
- tmMatchesMap jako normalna mapa (nie ptr_map)
- REJECTED LCP array
- !important! rezygnacja z ptr_vector
- zwracanie wektorów
- powyrzucać using namespace std
- profiling

